{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the Day Three project is a logical progression from Day Two's simple linear regression, with one \n",
    "# independent variable, to multiple linear regression where we use more than one independent variable. This is closer\n",
    "# to what you'll see in the real world where we usually have a number of variables in our dataset.\n",
    "#\n",
    "# Since this is similar to Day Two, we'll be using pretty much the same libraries and methods.\n",
    "#\n",
    "# Start by importing the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     50 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.0+ KB\n",
      "x values look like  [[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']]\n",
      "y values look like  [192261.83 191792.06 191050.39]\n"
     ]
    }
   ],
   "source": [
    "# Next, we'll bring in the dataset\n",
    "# Remember to put your specific path to where you downloaded the datasets\n",
    "dataset = pd.read_csv('../Materials/datasets/50_Startups.csv')\n",
    "\n",
    "# Let's look at the dataset to see what it's made up of\n",
    "print dataset.iloc[:3]\n",
    "\n",
    "# and look at the information about the data\n",
    "dataset.info()\n",
    "\n",
    "x = dataset.iloc[ :, :-1].values\n",
    "y = dataset.iloc[ : , 4 ].values\n",
    "\n",
    "# so the x variable is a data frame containing all but the last column of the dataset\n",
    "print \"x values look like \", x[:3]\n",
    "\n",
    "# and the y vector contains only the data from the last column of the dataset\n",
    "print \"y values look like \", y[:3]\n",
    "\n",
    "# so we see that x contains the independent variables (input variables) used for our regression model, and\n",
    "# y contains the dependent variable (output variable) of the model. Here's a quick refresher regarding independent\n",
    "# and dependent variables:\n",
    "#\n",
    "# The dependent variable is what is being studied and measured in the experiment. It's what changes as a result of \n",
    "# the changes to the independent variable. An example of a dependent variable is how tall you are at different ages. \n",
    "# The dependent variable (height) depends on the independent variable (age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique category variables =  ['New York' 'California' 'Florida']\n",
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/preprocessing/_encoders.py:385: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# from looking at the data we can see there is one column that is non-numeric, the State column, and is known as\n",
    "# categorical data. Since the regression model requires numerical data, we need to encode the categorical\n",
    "# data \n",
    "#\n",
    "# first let's see how many unique values there are for the category variable\n",
    "print 'The unique category variables = ', dataset.State.unique()\n",
    "#\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "x[ : , 3] = labelencoder.fit_transform(x[:,3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "#onehotencoder = OneHotEncoder(categories=\"auto\")\n",
    "x = onehotencoder.fit_transform(x).toarray()\n",
    "# now let's look at the encoding\n",
    "print x[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05 4.7178410e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05 4.4389853e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05 4.0793454e+05]]\n"
     ]
    }
   ],
   "source": [
    "# here we're removing one of the three dummy variables resulting from transforming the category variable values\n",
    "# by removing one of the three dummay variables. we're saying all three values can still be represented as follows:\n",
    "# category variables are now in cols 1-3 because there are only three unique values to the category variable, \n",
    "# 'New York', 'California', and 'Florida'. What the dummy variable trap says is you don't need 3 dummy variables for\n",
    "# three unique values, you only need 2: [1,0] = 'New York', [0,1] = California', [0,0] = 'Florida'.\n",
    "#\n",
    "# Personal note: this is really not needed, the regression fitting models will work fine whether there are three \n",
    "# dummy variables or two, plus, you have to know how many unique values there are to make this work.\n",
    "# \n",
    "x_trap = x[ : , 1: ]\n",
    "\n",
    "print x_trap[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 5) (40,)\n",
      "(10, 5) (10,)\n",
      "[[1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05 1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04 2.4974455e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05 2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04 1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05 4.0793454e+05]\n",
      " [0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05 3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04 1.8526510e+05]\n",
      " [0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05 8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05 3.0331926e+05]\n",
      " [1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04 3.6616842e+05]]\n"
     ]
    }
   ],
   "source": [
    "# OK, we really haven't done anything yet except make all of the values in the dataset numeric so we can use them\n",
    "# in a regression model. Now we create a training and test set for our regression model.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_trap, y, test_size=0.2, random_state = 0)\n",
    "\n",
    "print x_train.shape, y_train.shape\n",
    "print x_test.shape, y_test.shape\n",
    "\n",
    "print x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept a0 = 42554.1676\n",
      "('The coefficient a1 = ', array([-9.59284160e+02,  6.99369053e+02,  7.73467193e-01,  3.28845975e-02,\n",
      "        3.66100259e-02]))\n"
     ]
    }
   ],
   "source": [
    "# Now we fit a regression model to our training set that include multiple independent variables\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train, y_train)\n",
    "# let's look at the model coefficients\n",
    "print (\"The intercept a0 = %.4f\" % regressor.intercept_)\n",
    "print (\"The coefficient a1 = \", regressor.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The forcasted data = ', array([103015.20159796, 132582.27760816, 132447.73845175,  71976.09851259,\n",
      "       178537.48221055, 116161.24230164,  67851.69209676,  98791.73374687,\n",
      "       113969.43533012, 167921.06569551]))\n",
      "The R-squared determination for the prediction (out of 100) = 0.9347\n"
     ]
    }
   ],
   "source": [
    "# now that we have a basic linear regression model based on the training data, we can use the model to\n",
    "# generate some forecasted, or predicted, data items based on new input data from our test dataset\n",
    "#\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "print (\"The forcasted data = \", y_pred)\n",
    "\n",
    "# now let's look at how good the prediction is from our model\n",
    "# the R-squared value is called the coefficient of determination and is a sum of squares calculation of the\n",
    "# residuals between the predicted y values and the actual y values in our y_test dataset. The closer to 100 (exact match)\n",
    "# the better the model is at predicting the dependent variable y given a set of indpendent variables {x0, x1, ..., xn}\n",
    "print (\"The R-squared determination for the prediction (out of 100) = %.4f\" % regressor.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
