{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Toolkit for Data Analytics\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook contains a collection of various examples using Pandas for data collection and manipulation. \n",
    "\n",
    "The homepage for Pandas can be found at: \n",
    "https://pandas.pydata.org\n",
    "\n",
    "Many of the examples in this toolkit come from various Data School videos:\n",
    "https://www.dataschool.io  \n",
    "  \n",
    "Additional references and examples come from the *Python Data Science Handbook* by Jake VanderPlas  \n",
    "https://github.com/jakevdp/PythonDataScienceHandbook  \n",
    "\n",
    "Have Fun!!!\n",
    "\n",
    "* [Setup and Datasets](#setup_and_datasets)  \n",
    "* [Numpy Arrays and Basic Pandas Objects](#numpy_arrays_and_basic_pandas_objects)  \n",
    "* [Reading and Writing Data](#reading_and_writing_data)  \n",
    "* [Working with Rows and Columns](#working_with_rows_and_columns)  \n",
    "* [Filters and Sorting](#filters_and_sorting)  \n",
    "* [Indexing](#indexing)  \n",
    "* [Concat and Append](#concat_append)  \n",
    "* [Merge and Join](#merge_join)  \n",
    "* [Aggregation and Grouping](#aggregate_group)  \n",
    "* [Working with Dates and Times](#dates_and_times)  \n",
    "* [Python Data Structures for Data Analysis](#python_data_structures)\n",
    "* [Special Features](#special_features)  \n",
    "    + [Element-wise Data Operations](#data_operations)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup_and_datasets'></a>\n",
    "## Setup and Datasets\n",
    "This next section will set up the libraries used throughout the notebook, as well as, introduce the various datasets used in the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:29:33.486634Z",
     "start_time": "2020-03-30T19:29:31.636285Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:10: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chip orders dataset looks like:\n",
      "(4622, 5)\n",
      "   order_id  quantity                     item_name choice_description  \\\n",
      "0         1         1  Chips and Fresh Tomato Salsa                NaN   \n",
      "1         1         1                          Izze       [Clementine]   \n",
      "\n",
      "  item_price  \n",
      "0     $2.39   \n",
      "1     $3.39   \n",
      "\n",
      "The ufo reports dataset looks like:\n",
      "(18241, 5)\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "\n",
      "The movie ratings dataset looks like:\n",
      "(979, 6)\n",
      "   star_rating                     title content_rating  genre  duration  \\\n",
      "0          9.3  The Shawshank Redemption              R  Crime       142   \n",
      "1          9.2             The Godfather              R  Crime       175   \n",
      "\n",
      "                                         actors_list  \n",
      "0  [u'Tim Robbins', u'Morgan Freeman', u'Bob Gunt...  \n",
      "1    [u'Marlon Brando', u'Al Pacino', u'James Caan']  \n",
      "\n",
      "The alcohol consumption by country dataset looks like:\n",
      "(193, 6)\n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n"
     ]
    }
   ],
   "source": [
    "# import the main libraries to be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# datasets\n",
    "# There are various datasets used in the following examples. some of the datasets are accessed from the local\n",
    "# files system, but some datasets are access online from the repository \n",
    "#\n",
    "# Chipolet chip orders\n",
    "chips = pd.read_table('http://bit.ly/chiporders')\n",
    "print(\"The chip orders dataset looks like:\")\n",
    "print(chips.shape)\n",
    "print(chips.head(2))\n",
    "#\n",
    "# UFO sightings\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "print(\"\\nThe ufo reports dataset looks like:\")\n",
    "print(ufo.shape)\n",
    "print(ufo.head(2))\n",
    "#\n",
    "# movie ratings from IMDB\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "print(\"\\nThe movie ratings dataset looks like:\")\n",
    "print(movies.shape)\n",
    "print(movies.head(2))\n",
    "#\n",
    "# alcohol consumption by country\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "print(\"\\nThe alcohol consumption by country dataset looks like:\")\n",
    "print(drinks.shape)\n",
    "print(drinks.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='numpy_arrays_and_basic_pandas_objects'></a>\n",
    "## NumPy Arrays and Basic Pandas Objects\n",
    "A separate notebook was created to provide numerous examples on the basic Python data structures of NumPy arrays\n",
    "and Pandas objects.\n",
    "\n",
    "See [PythonDataStructures](PythonDataStructures.ipynb)\n",
    "\n",
    "The examples are from the excellent reference site by Jake VanderPlas for the \"Python Data Science Handbook\"\n",
    "https://github.com/jakevdp/PythonDataScienceHandbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reading_and_writing_data'></a>\n",
    "## Reading and Writing Data\n",
    "A separate notebook was created earlier that provides numerous examples on reading and writing data with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [ReadingWritingData](ReadingWritingData.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='working_with_rows_and_columns'></a>\n",
    "## Working with Rows and Columns\n",
    "This section include basic mechanics for working with data by rows or columns in a Pandas DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Ithaca\n",
      "1    Willingboro\n",
      "Name: City, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n",
      "0         Ithaca\n",
      "1    Willingboro\n",
      "Name: City, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# each column of a pandas dataframe is a series\n",
    "# using bracket notation\n",
    "print(ufo['City'].head(2))\n",
    "print(type(ufo['City']))\n",
    "#\n",
    "# using dot notation\n",
    "# only works if there are no spaces in the attribute (column) name, otherwise use bracket notation\n",
    "# also only works if there is no conflict with a built-in attribute name\n",
    "print(ufo.City.head(2)) \n",
    "print(type(ufo.City))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time'], dtype='object')\n",
      "Index(['City', 'Colors_Reported', 'Shape_Reported', 'State', 'Time'], dtype='object')\n",
      "Index(['city', 'colors reported', 'share reported', 'state', 'time'], dtype='object')\n",
      "          city colors reported share reported state             time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "Index(['city', 'colors_reported', 'share_reported', 'state', 'time'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# renaming columns\n",
    "print(ufo.columns) # list the column names\n",
    "#\n",
    "# remove the spaces from the column names\n",
    "ufo.rename(columns = {'Colors Reported':'Colors_Reported', 'Shape Reported':'Shape_Reported'}, inplace=True)\n",
    "print(ufo.columns)\n",
    "#\n",
    "# change multiple column names at once\n",
    "ufo_cols = ['city', 'colors reported', 'share reported', 'state', 'time']\n",
    "ufo.columns = ufo_cols\n",
    "print(ufo.columns)\n",
    "#\n",
    "# change column names on data read\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports', names=ufo_cols, header=0) # header = 0th row\n",
    "print(ufo.head(2))\n",
    "#\n",
    "# change names on a multitude of column names at once\n",
    "ufo.columns = ufo.columns.str.replace(' ', '_')\n",
    "print(ufo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city share_reported state             time\n",
      "0       Ithaca       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro          OTHER    NJ  6/30/1930 20:00\n",
      "  share_reported             time\n",
      "0       TRIANGLE   6/1/1930 22:00\n",
      "1          OTHER  6/30/1930 20:00\n",
      "   A1\n",
      "0   1\n",
      "1   2\n",
      "2   3\n",
      "   B2  C2\n",
      "0   2   5\n",
      "1   4   5\n",
      "2   8   5\n"
     ]
    }
   ],
   "source": [
    "# deleting columns\n",
    "# single column\n",
    "ufo.drop('colors_reported', axis=1, inplace=True) # axis: 0=rows, 1=cols\n",
    "print(ufo.head(2))\n",
    "#\n",
    "# multiple columns\n",
    "ufo.drop(['city', 'state'], axis=1, inplace=True)\n",
    "print(ufo.head(2))\n",
    "#\n",
    "# using conditions to delete columns\n",
    "df = pd.DataFrame({\"A1\": [1,2,3],\n",
    "                   \"B2\": [2,4,8],\n",
    "                   \"C2\": [5,5,5]})\n",
    "cols_to_drop = [cname for cname in df.columns if cname.endswith(\"2\")]\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df)\n",
    "#\n",
    "# selecting what columns to keep and delete everything else\n",
    "df = pd.DataFrame({\"A1\": [1,2,3],\n",
    "                   \"B2\": [2,4,8],\n",
    "                   \"C2\": [5,5,5]})\n",
    "cols_to_keep = [cname for cname in df.columns if cname.endswith(\"2\")]\n",
    "df = df[cols_to_keep]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  share_reported             time\n",
      "2           OVAL  2/15/1931 14:00\n",
      "3           DISK   6/1/1931 13:00\n"
     ]
    }
   ],
   "source": [
    "# deleting rows\n",
    "ufo.drop([0,1], axis=0, inplace=True) # list the index values/names, axis=0 is default\n",
    "print(ufo.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  2  1\n",
      "1  2  4  2\n",
      "2  3  8  3\n",
      "   A  B  C  D\n",
      "0  1  2  1  1\n",
      "1  2  4  2  2\n",
      "2  3  8  3  3\n",
      "   A  B  C  D\n",
      "0  1  2  1  1\n",
      "1  2  4  2  2\n",
      "2  3  8  3  3\n",
      "   A  B  C  D  E\n",
      "0  1  2  1  1  1\n",
      "1  2  4  2  2  2\n",
      "2  3  8  3  3  3\n",
      "   A  B  C  D  E   F\n",
      "0  1  2  1  1  1   4\n",
      "1  2  4  2  2  2   8\n",
      "2  3  8  3  3  3  16\n"
     ]
    }
   ],
   "source": [
    "# adding columns\n",
    "# three basic approaches - bracket indexing, loc, and assign\n",
    "#\n",
    "df = pd.DataFrame({\"A\": [1,2,3],\n",
    "                   \"B\": [2,4,8]})\n",
    "#\n",
    "df[\"C\"] = [1,2,3]         # explicit bracket notation for the new column, this modifies the original dataframe\n",
    "print(df)\n",
    "df.loc[:, \"D\"] = [1,2,3]  # use loc to do the same explicit column addition, this modifies the original dataframe\n",
    "print(df)\n",
    "df_new = df.assign(E=[1,2,3]) # returns a new dataframe with the new column added, the original is NOT modified\n",
    "print(df)\n",
    "print(df_new)\n",
    "#\n",
    "# adding a new column based on an existing column\n",
    "df_newer = df_new.assign(F=lambda idf: idf[\"B\"] * 2)\n",
    "print(df_newer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  C  B\n",
      "0  1  1  2\n",
      "1  2  2  4\n",
      "2  3  3  8\n"
     ]
    }
   ],
   "source": [
    "# inserting columns\n",
    "df = pd.DataFrame({\"A\": [1,2,3],\n",
    "                   \"B\": [2,4,8]})\n",
    "df.insert(loc=1, column=\"C\", value=[1,2,3])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T18:45:57.715915Z",
     "start_time": "2020-04-01T18:45:55.521627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country                          object\n",
      "beer_servings                     int64\n",
      "spirit_servings                   int64\n",
      "wine_servings                     int64\n",
      "total_litres_of_pure_alcohol    float64\n",
      "continent                        object\n",
      "dtype: object\n",
      "beer_servings    float64\n",
      "dtype: object\n",
      "country                          object\n",
      "beer_servings                   float64\n",
      "spirit_servings                   int64\n",
      "wine_servings                     int64\n",
      "total_litres_of_pure_alcohol    float64\n",
      "continent                        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# changing the type of the data in a column\n",
    "print(drinks.dtypes)\n",
    "drinks2 = pd.DataFrame()\n",
    "drinks2['beer_servings'] = drinks.beer_servings.astype(float)\n",
    "print(drinks2.dtypes)\n",
    "#\n",
    "# can change the datat type when reading in the data as well\n",
    "drinks2 = pd.read_csv('http://bit.ly/drinksbycountry', dtype={'beer_servings':float})\n",
    "print(drinks2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='filters_and_sorting'></a>\n",
    "## Filters and Sorting\n",
    "How to sort a DataFrame or Series and apply filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542     (500) Days of Summer\n",
      "5               12 Angry Men\n",
      "201         12 Years a Slave\n",
      "698                127 Hours\n",
      "110    2001: A Space Odyssey\n",
      "Name: title, dtype: object\n",
      "542     (500) Days of Summer\n",
      "5               12 Angry Men\n",
      "201         12 Years a Slave\n",
      "698                127 Hours\n",
      "110    2001: A Space Odyssey\n",
      "Name: title, dtype: object\n",
      "864               [Rec]\n",
      "526                Zulu\n",
      "615          Zombieland\n",
      "677              Zodiac\n",
      "955    Zero Dark Thirty\n",
      "Name: title, dtype: object\n",
      "     star_rating                        title content_rating    genre  \\\n",
      "389          8.0                       Freaks        UNRATED    Drama   \n",
      "338          8.0          Battleship Potemkin        UNRATED  History   \n",
      "258          8.1  The Cabinet of Dr. Caligari        UNRATED    Crime   \n",
      "293          8.1                    Duck Soup         PASSED   Comedy   \n",
      "88           8.4                      The Kid      NOT RATED   Comedy   \n",
      "\n",
      "     duration                                        actors_list  \n",
      "389        64  [u'Wallace Ford', u'Leila Hyams', u'Olga Bacla...  \n",
      "338        66  [u'Aleksandr Antonov', u'Vladimir Barsky', u'G...  \n",
      "258        67  [u'Werner Krauss', u'Conrad Veidt', u'Friedric...  \n",
      "293        68    [u'Groucho Marx', u'Harpo Marx', u'Chico Marx']  \n",
      "88         68  [u'Charles Chaplin', u'Edna Purviance', u'Jack...  \n",
      "     star_rating                           title content_rating      genre  \\\n",
      "713          7.6                 The Jungle Book       APPROVED  Animation   \n",
      "513          7.8  Invasion of the Body Snatchers       APPROVED     Horror   \n",
      "272          8.1                     The Killing       APPROVED      Crime   \n",
      "703          7.6                         Dracula       APPROVED     Horror   \n",
      "612          7.7              A Hard Day's Night       APPROVED     Comedy   \n",
      "\n",
      "     duration                                        actors_list  \n",
      "713        78  [u'Phil Harris', u'Sebastian Cabot', u'Louis P...  \n",
      "513        80  [u'Kevin McCarthy', u'Dana Wynter', u'Larry Ga...  \n",
      "272        85  [u'Sterling Hayden', u'Coleen Gray', u'Vince E...  \n",
      "703        85  [u'Bela Lugosi', u'Helen Chandler', u'David Ma...  \n",
      "612        87  [u'John Lennon', u'Paul McCartney', u'George H...  \n"
     ]
    }
   ],
   "source": [
    "# performing a sort\n",
    "# single column (Series) in dot notation\n",
    "print(movies.title.sort_values().head())\n",
    "#\n",
    "# single column (Series) in bracket notation\n",
    "print(movies['title'].sort_values().head())\n",
    "print(movies['title'].sort_values(ascending=False).head())\n",
    "#\n",
    "# whole dataframe by a single column (Series)\n",
    "print(movies.sort_values('duration').head())\n",
    "#\n",
    "# whole dataframe by multiple columns\n",
    "print(movies.sort_values(['content_rating','duration']).head(5)) # sorts by first list element, then second, then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    star_rating                                          title content_rating  \\\n",
      "2           9.1                         The Godfather: Part II              R   \n",
      "7           8.9  The Lord of the Rings: The Return of the King          PG-13   \n",
      "17          8.7                                  Seven Samurai        UNRATED   \n",
      "78          8.4                    Once Upon a Time in America              R   \n",
      "85          8.4                             Lawrence of Arabia             PG   \n",
      "\n",
      "        genre  duration                                        actors_list  \n",
      "2       Crime       200  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7   Adventure       201  [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17      Drama       207  [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78      Crime       229  [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85  Adventure       216  [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "2         Crime\n",
      "7     Adventure\n",
      "17        Drama\n",
      "78        Crime\n",
      "85    Adventure\n",
      "Name: genre, dtype: object\n",
      "2         Crime\n",
      "7     Adventure\n",
      "17        Drama\n",
      "78        Crime\n",
      "85    Adventure\n",
      "Name: genre, dtype: object\n",
      "        genre  duration\n",
      "2       Crime       200\n",
      "7   Adventure       201\n",
      "17      Drama       207\n",
      "78      Crime       229\n",
      "85  Adventure       216\n",
      "     star_rating               title content_rating  genre  duration  \\\n",
      "17           8.7       Seven Samurai        UNRATED  Drama       207   \n",
      "157          8.2  Gone with the Wind              G  Drama       238   \n",
      "476          7.8              Hamlet          PG-13  Drama       242   \n",
      "\n",
      "                                           actors_list  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "    star_rating                                          title content_rating  \\\n",
      "2           9.1                         The Godfather: Part II              R   \n",
      "5           8.9                                   12 Angry Men      NOT RATED   \n",
      "7           8.9  The Lord of the Rings: The Return of the King          PG-13   \n",
      "9           8.9                                     Fight Club              R   \n",
      "13          8.8                                   Forrest Gump          PG-13   \n",
      "\n",
      "        genre  duration                                        actors_list  \n",
      "2       Crime       200  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "5       Drama        96  [u'Henry Fonda', u'Lee J. Cobb', u'Martin Bals...  \n",
      "7   Adventure       201  [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "9       Drama       139  [u'Brad Pitt', u'Edward Norton', u'Helena Bonh...  \n",
      "13      Drama       142    [u'Tom Hanks', u'Robin Wright', u'Gary Sinise']  \n",
      "   star_rating                     title content_rating   genre  duration  \\\n",
      "0          9.3  The Shawshank Redemption              R   Crime       142   \n",
      "1          9.2             The Godfather              R   Crime       175   \n",
      "2          9.1    The Godfather: Part II              R   Crime       200   \n",
      "3          9.0           The Dark Knight          PG-13  Action       152   \n",
      "4          8.9              Pulp Fiction              R   Crime       154   \n",
      "\n",
      "                                         actors_list  \n",
      "0  [u'Tim Robbins', u'Morgan Freeman', u'Bob Gunt...  \n",
      "1    [u'Marlon Brando', u'Al Pacino', u'James Caan']  \n",
      "2  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "3  [u'Christian Bale', u'Heath Ledger', u'Aaron E...  \n",
      "4  [u'John Travolta', u'Uma Thurman', u'Samuel L....  \n"
     ]
    }
   ],
   "source": [
    "# filtering dataframe rows by column\n",
    "# only rows with duration > 200\n",
    "print(movies[movies.duration >= 200].head(5))\n",
    "#\n",
    "# extracting one or more columns of filtered rows\n",
    "# dot notation\n",
    "print(movies[movies.duration >= 200].genre.head(5))\n",
    "#\n",
    "# bracket notation - single column\n",
    "print(movies[movies.duration >= 200]['genre'].head(5))\n",
    "#\n",
    "# bracket notation - multiple columns\n",
    "print(movies.loc[movies.duration >= 200,['genre', 'duration']].head(5))\n",
    "#\n",
    "# multiple filter criteria - use of 'and' (&) and 'or' (|)\n",
    "print(movies[(movies.duration >= 200) & (movies.genre == 'Drama')].head(5))\n",
    "#\n",
    "print(movies[(movies.duration >= 200) | (movies.genre == 'Drama')].head(5))\n",
    "#\n",
    "# multiple 'or' filters - a different approach\n",
    "print(movies[movies.genre.isin(['Crime', 'Drama', 'Action'])].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='indexing'></a>\n",
    "## Indexing\n",
    "This section shows examples related to accessing specific 'slices' or 'locations' of pandas dataframes.  \n",
    "  \n",
    "Here is additional reference information from the Python Data Sceince Handbook by Jake VanderPlas  \n",
    "[Data Indexing and Selection](PythonDataScienceHandbook/03.02-Data-Indexing-and-Selection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City                       Ithaca\n",
      "Colors Reported               NaN\n",
      "Shape Reported           TRIANGLE\n",
      "State                          NY\n",
      "Time               6/1/1930 22:00\n",
      "Name: 0, dtype: object\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "0                  Ithaca\n",
      "1             Willingboro\n",
      "2                 Holyoke\n",
      "3                 Abilene\n",
      "4    New York Worlds Fair\n",
      "Name: City, dtype: object\n",
      "                   City State\n",
      "0                Ithaca    NY\n",
      "1           Willingboro    NJ\n",
      "2               Holyoke    CO\n",
      "3               Abilene    KS\n",
      "4  New York Worlds Fair    NY\n",
      "                   City Colors Reported Shape Reported State\n",
      "0                Ithaca             NaN       TRIANGLE    NY\n",
      "1           Willingboro             NaN          OTHER    NJ\n",
      "2               Holyoke             NaN           OVAL    CO\n",
      "3               Abilene             NaN           DISK    KS\n",
      "4  New York Worlds Fair             NaN          LIGHT    NY\n",
      "         City Colors Reported Shape Reported State             Time\n",
      "1694  Oakland             NaN          CIGAR    CA  7/21/1968 14:00\n",
      "2144  Oakland             NaN           DISK    CA   8/19/1971 0:00\n",
      "4686  Oakland             NaN          LIGHT    MD    6/1/1982 0:00\n",
      "7293  Oakland             NaN          LIGHT    CA  3/28/1994 17:00\n",
      "8488  Oakland             NaN            NaN    CA  8/10/1995 21:45\n",
      "1694    CA\n",
      "2144    CA\n",
      "4686    MD\n",
      "7293    CA\n",
      "8488    CA\n",
      "Name: State, dtype: object\n",
      "     State             Time\n",
      "1694    CA  7/21/1968 14:00\n",
      "2144    CA   8/19/1971 0:00\n",
      "4686    MD    6/1/1982 0:00\n",
      "7293    CA  3/28/1994 17:00\n",
      "8488    CA  8/10/1995 21:45\n"
     ]
    }
   ],
   "source": [
    "# using loc - selecting rows and columns by label\n",
    "#\n",
    "# UFO sightings\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "print(ufo.loc[0,:]) # row zero, all columns\n",
    "#\n",
    "print(ufo.loc[0:2, :]) # rows 0-2 inclusive, all columns\n",
    "#\n",
    "print(ufo.loc[:, 'City'].head(5)) # all rows, 'City' column\n",
    "#\n",
    "print(ufo.loc[:, ['City', 'State']].head(5)) # all rows, 'City' and 'State' columns\n",
    "#\n",
    "print(ufo.loc[:, 'City':'State'].head(5)) # all rows, columns 'City' through 'State'\n",
    "#\n",
    "# loc with boolean conditions\n",
    "print(ufo.loc[ufo.City=='Oakland', :].head(5)) # all rows where city==oakland, all columns\n",
    "#\n",
    "print(ufo.loc[ufo.City=='Oakland', 'State'].head(5)) # all rows where city==oakland, only the 'State' column\n",
    "#\n",
    "print(ufo.loc[ufo.City=='Oakland', ['State','Time']].head(5)) # rows where city==oakland, 'State' and 'Time' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   City State\n",
      "0                Ithaca    NY\n",
      "1           Willingboro    NJ\n",
      "2               Holyoke    CO\n",
      "3               Abilene    KS\n",
      "4  New York Worlds Fair    NY\n",
      "                   City Colors Reported Shape Reported State\n",
      "0                Ithaca             NaN       TRIANGLE    NY\n",
      "1           Willingboro             NaN          OTHER    NJ\n",
      "2               Holyoke             NaN           OVAL    CO\n",
      "3               Abilene             NaN           DISK    KS\n",
      "4  New York Worlds Fair             NaN          LIGHT    NY\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n"
     ]
    }
   ],
   "source": [
    "# using iloc - selection by integer position\n",
    "\n",
    "print(ufo.iloc[:, [0,3]].head(5))  # all rows, columns at position 0 and 3\n",
    "#\n",
    "print(ufo.iloc[:, 0:4].head(5))  # all rows, columns at position 0-4, exclusive (means only 0-3 selected)\n",
    "#\n",
    "print(ufo.iloc[0:3, :]) # rows 0-3 exclusive (means only 0-2), and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1    89\n",
      "Name: beer_servings, dtype: int64\n",
      "0     0\n",
      "1    89\n",
      "Name: beer_servings, dtype: int64\n",
      "   beer_servings  spirit_servings\n",
      "0              0                0\n",
      "1             89              132\n",
      "   beer_servings  spirit_servings\n",
      "0              0                0\n",
      "1             89              132\n"
     ]
    }
   ],
   "source": [
    "# using ix - selection by mix of labels and integer position (ix IS BEING DEPRECATED!)\n",
    "# instead use loc and iloc and positional indexing and label indexing\n",
    "\n",
    "# mixed label and integer position - multiple rows, single column\n",
    "print(drinks.loc[drinks.index[[0,1]], 'beer_servings']) # row labels by position (0-1 inclusive), column by label\n",
    "print(drinks.iloc[0:2, drinks.columns.get_loc('beer_servings')]) # row positions, column by position by label\n",
    "#\n",
    "# mixed label and integer position - multiple rows, multiple columns\n",
    "print(drinks.loc[drinks.index[[0,1]], ['beer_servings', 'spirit_servings']]) # row labels by position (0-1 inclusive), column by label\n",
    "print(drinks.iloc[0:2, [drinks.columns.get_loc(c) for c in ['beer_servings','spirit_servings']]]) # row positions, column by position by label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='concat_append'></a>\n",
    "## Concat and Append  \n",
    "Pandas provides powerful operations for combining datasets by concatenating Series or DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         IthacaNY\n",
      "1    WillingboroNJ\n",
      "dtype: object\n",
      "0    2\n",
      "1    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# concatenating two columns using simple operations\n",
    "#\n",
    "# UFO sightings\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "# if strings, then you get the following\n",
    "print((ufo.City + ufo.State).head(2)) \n",
    "# if numbers, then the columns are added together\n",
    "print((chips.order_id + chips.quantity).head(2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is additional reference information from the Python Data Science Handbook by Jake VanderPlas  \n",
    "[Concat and Append](PythonDataScienceHandbook/03.06-Concat-And-Append.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merge_join'></a>\n",
    "## Merge and Join \n",
    "In addition to concatinating and appending datasets, Pandas also supports more sophisticated merge and join operations.  \n",
    "Here is additional reference information from the Python Data Science Handbook by Jake VaderPlas  \n",
    "[Merge and Join](PythonDataScienceHandbook/03.07-Merge-and-Join.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aggregate_group'></a>  \n",
    "## Aggregation and Grouping  \n",
    "Pandas supports the ability to perform summarization of large datasets by using computing aggregations like sum(), mean(), median(), min(), and max().  \n",
    "More sophisticated aggregations, including multiple layers of aggregations within a dataset, can be performed by grouping using groupby where you can perform split-apply-combine operations on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n"
     ]
    }
   ],
   "source": [
    "# and example of aggregation and grouping\n",
    "\n",
    "# use the drinks by country dataset\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "print(drinks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.16062176165804\n"
     ]
    }
   ],
   "source": [
    "# what is the average beer servings across all continents?\n",
    "print(drinks.beer_servings.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent\n",
      "Africa            61.471698\n",
      "Asia              37.045455\n",
      "Europe           193.777778\n",
      "North America    145.434783\n",
      "Oceania           89.687500\n",
      "South America    175.083333\n",
      "Name: beer_servings, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# what is the average beer servings by continent?\n",
    "print(drinks.groupby('continent').beer_servings.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               count  min  max        mean\n",
      "continent                                 \n",
      "Africa            53    0  376   61.471698\n",
      "Asia              44    0  247   37.045455\n",
      "Europe            45    0  361  193.777778\n",
      "North America     23    1  285  145.434783\n",
      "Oceania           16    0  306   89.687500\n",
      "South America     12   93  333  175.083333\n"
     ]
    }
   ],
   "source": [
    "# what is the number, min, max, and average number of beer servings by continent?\n",
    "print(drinks.groupby('continent').beer_servings.agg(['count','min','max','mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               beer_servings  spirit_servings  wine_servings  \\\n",
      "continent                                                      \n",
      "Africa             61.471698        16.339623      16.264151   \n",
      "Asia               37.045455        60.840909       9.068182   \n",
      "Europe            193.777778       132.555556     142.222222   \n",
      "North America     145.434783       165.739130      24.521739   \n",
      "Oceania            89.687500        58.437500      35.625000   \n",
      "South America     175.083333       114.750000      62.416667   \n",
      "\n",
      "               total_litres_of_pure_alcohol  \n",
      "continent                                    \n",
      "Africa                             3.007547  \n",
      "Asia                               2.170455  \n",
      "Europe                             8.617778  \n",
      "North America                      5.995652  \n",
      "Oceania                            3.381250  \n",
      "South America                      6.308333  \n"
     ]
    }
   ],
   "source": [
    "# what is the average of all alcohol servings by continent?\n",
    "print(drinks.groupby('continent').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent      country                 \n",
      "Africa         Algeria                      25\n",
      "               Angola                      217\n",
      "               Benin                        34\n",
      "               Botswana                    173\n",
      "               Burkina Faso                 25\n",
      "               Burundi                      88\n",
      "               Cabo Verde                  144\n",
      "               Cameroon                    147\n",
      "               Central African Republic     17\n",
      "               Chad                         15\n",
      "               Comoros                       1\n",
      "               Congo                        76\n",
      "               Cote d'Ivoire                37\n",
      "               DR Congo                     32\n",
      "               Djibouti                     15\n",
      "               Egypt                         6\n",
      "               Equatorial Guinea            92\n",
      "               Eritrea                      18\n",
      "               Ethiopia                     20\n",
      "               Gabon                       347\n",
      "               Gambia                        8\n",
      "               Ghana                        31\n",
      "               Guinea                        9\n",
      "               Guinea-Bissau                28\n",
      "               Kenya                        58\n",
      "               Lesotho                      82\n",
      "               Liberia                      19\n",
      "               Libya                         0\n",
      "               Madagascar                   26\n",
      "               Malawi                        8\n",
      "                                          ... \n",
      "North America  Trinidad & Tobago           197\n",
      "               USA                         249\n",
      "Oceania        Australia                   261\n",
      "               Cook Islands                  0\n",
      "               Fiji                         77\n",
      "               Kiribati                     21\n",
      "               Marshall Islands              0\n",
      "               Micronesia                   62\n",
      "               Nauru                        49\n",
      "               New Zealand                 203\n",
      "               Niue                        188\n",
      "               Palau                       306\n",
      "               Papua New Guinea             44\n",
      "               Samoa                       105\n",
      "               Solomon Islands              56\n",
      "               Tonga                        36\n",
      "               Tuvalu                        6\n",
      "               Vanuatu                      21\n",
      "South America  Argentina                   193\n",
      "               Bolivia                     167\n",
      "               Brazil                      245\n",
      "               Chile                       130\n",
      "               Colombia                    159\n",
      "               Ecuador                     162\n",
      "               Guyana                       93\n",
      "               Paraguay                    213\n",
      "               Peru                        163\n",
      "               Suriname                    128\n",
      "               Uruguay                     115\n",
      "               Venezuela                   333\n",
      "Name: beer_servings, Length: 193, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# what is the average beer servings by country by continent?\n",
    "print(drinks.groupby(['continent','country']).beer_servings.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is additional reference information from the Python Data Science Handbook by Jake VanderPlas  \n",
    "[Aggregation and Grouping](PythonDataScienceHandbook/03.08-Aggregation-and-Grouping.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dates_and_times'></a>\n",
    "## Dates and Times\n",
    "\n",
    "This section describes basic capabilities when working with date and time values. \n",
    "  \n",
    "https://pandas.pydata.org/docs/user_guide/timeseries.html  \n",
    "  \n",
    "https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:40:23.796144Z",
     "start_time": "2020-03-30T19:40:23.679654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   City Colors Reported Shape Reported State             Time\n",
      "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00\n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00\n",
      "City               object\n",
      "Colors Reported    object\n",
      "Shape Reported     object\n",
      "State              object\n",
      "Time               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ufo.head())\n",
    "print(ufo.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:32:02.208145Z",
     "start_time": "2020-03-30T20:32:02.186355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   City Colors Reported Shape Reported State  \\\n",
      "0                Ithaca             NaN       TRIANGLE    NY   \n",
      "1           Willingboro             NaN          OTHER    NJ   \n",
      "2               Holyoke             NaN           OVAL    CO   \n",
      "3               Abilene             NaN           DISK    KS   \n",
      "4  New York Worlds Fair             NaN          LIGHT    NY   \n",
      "\n",
      "                 Time  \n",
      "0 1930-06-01 22:00:00  \n",
      "1 1930-06-30 20:00:00  \n",
      "2 1931-02-15 14:00:00  \n",
      "3 1931-06-01 13:00:00  \n",
      "4 1933-04-18 19:00:00  \n",
      "City                       object\n",
      "Colors Reported            object\n",
      "Shape Reported             object\n",
      "State                      object\n",
      "Time               datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convert date/time strings to datetime objects \n",
    "# can detect the day, month, year from the string and do the conversion correctly\n",
    "ufo['Time'] = pd.to_datetime(ufo.Time)\n",
    "print(ufo.head())\n",
    "print(ufo.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T19:45:02.832202Z",
     "start_time": "2020-03-30T19:45:02.813214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22\n",
       "1    20\n",
       "2    14\n",
       "3    13\n",
       "4    19\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.Time.dt.hour.head()\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.hour.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:03:40.333997Z",
     "start_time": "2020-03-30T20:03:40.313267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    0\n",
       "2    6\n",
       "3    0\n",
       "4    1\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.Time.dt.weekday.head()\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.weekday.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:42:26.237137Z",
     "start_time": "2020-03-30T20:42:26.112259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999-01-01 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Colors Reported</th>\n",
       "      <th>Shape Reported</th>\n",
       "      <th>State</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>Loma Rica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>CA</td>\n",
       "      <td>1999-01-01 02:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>Bauxite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>1999-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>Florence</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CYLINDER</td>\n",
       "      <td>SC</td>\n",
       "      <td>1999-01-01 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>Lake Henshaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CIGAR</td>\n",
       "      <td>CA</td>\n",
       "      <td>1999-01-01 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>Wilmington Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIGHT</td>\n",
       "      <td>GA</td>\n",
       "      <td>1999-01-01 17:15:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    City Colors Reported Shape Reported State  \\\n",
       "12832          Loma Rica             NaN          LIGHT    CA   \n",
       "12833            Bauxite             NaN            NaN    AR   \n",
       "12834           Florence             NaN       CYLINDER    SC   \n",
       "12835       Lake Henshaw             NaN          CIGAR    CA   \n",
       "12836  Wilmington Island             NaN          LIGHT    GA   \n",
       "\n",
       "                     Time  \n",
       "12832 1999-01-01 02:30:00  \n",
       "12833 1999-01-01 03:00:00  \n",
       "12834 1999-01-01 14:00:00  \n",
       "12835 1999-01-01 15:00:00  \n",
       "12836 1999-01-01 17:15:00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a timestamp to use in comparisons and time math\n",
    "ts = pd.to_datetime('1/1/1999')\n",
    "print(ts)\n",
    "\n",
    "ufo.loc[ufo.Time >= ts, :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:45:42.803743Z",
     "start_time": "2020-03-30T20:45:42.793468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-12-31 23:59:00\n",
      "1930-06-01 22:00:00\n",
      "25781\n"
     ]
    }
   ],
   "source": [
    "print(ufo.Time.max())\n",
    "print(ufo.Time.min())\n",
    "print((ufo.Time.max() - ufo.Time.min()).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:54:51.030651Z",
     "start_time": "2020-03-30T20:54:50.957157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   City Colors Reported Shape Reported State  \\\n",
      "0                Ithaca             NaN       TRIANGLE    NY   \n",
      "1           Willingboro             NaN          OTHER    NJ   \n",
      "2               Holyoke             NaN           OVAL    CO   \n",
      "3               Abilene             NaN           DISK    KS   \n",
      "4  New York Worlds Fair             NaN          LIGHT    NY   \n",
      "\n",
      "                 Time  Year  \n",
      "0 1930-06-01 22:00:00  1930  \n",
      "1 1930-06-30 20:00:00  1930  \n",
      "2 1931-02-15 14:00:00  1931  \n",
      "3 1931-06-01 13:00:00  1931  \n",
      "4 1933-04-18 19:00:00  1933  \n"
     ]
    }
   ],
   "source": [
    "ufo['Year'] = ufo.Time.dt.year\n",
    "print(ufo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T20:56:38.676658Z",
     "start_time": "2020-03-30T20:56:38.571675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930       2\n",
       "1931       2\n",
       "1933       1\n",
       "1934       1\n",
       "1935       1\n",
       "1936       2\n",
       "1937       2\n",
       "1939       3\n",
       "1941       2\n",
       "1942       3\n",
       "1943       5\n",
       "1944       8\n",
       "1945       9\n",
       "1946       8\n",
       "1947      41\n",
       "1948       9\n",
       "1949      19\n",
       "1950      31\n",
       "1951      21\n",
       "1952      52\n",
       "1953      36\n",
       "1954      55\n",
       "1955      33\n",
       "1956      46\n",
       "1957      78\n",
       "1958      53\n",
       "1959      57\n",
       "1960      67\n",
       "1961      50\n",
       "1962      72\n",
       "        ... \n",
       "1971     118\n",
       "1972     162\n",
       "1973     227\n",
       "1974     261\n",
       "1975     312\n",
       "1976     281\n",
       "1977     258\n",
       "1978     326\n",
       "1979     237\n",
       "1980     244\n",
       "1981     175\n",
       "1982     186\n",
       "1983     148\n",
       "1984     177\n",
       "1985     211\n",
       "1986     186\n",
       "1987     210\n",
       "1988     232\n",
       "1989     247\n",
       "1990     237\n",
       "1991     220\n",
       "1992     245\n",
       "1993     292\n",
       "1994     406\n",
       "1995    1344\n",
       "1996     851\n",
       "1997    1237\n",
       "1998    1743\n",
       "1999    2774\n",
       "2000    2635\n",
       "Name: Year, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a count of the number for each year, and then sort according to the Year (which is the index)\n",
    "ufo.Year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T16:12:49.871926Z",
     "start_time": "2020-04-01T16:12:40.937133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119c57050>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ufo.Year.value_counts().sort_index().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='python_data_structures'></a>\n",
    "## Python Data Structures for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook contains examples of basic Python data structures from the NumPy and Pandas libraries that are used frequently in data analysis. Many of the examples come from the excellent reference book by Jake VanderPlas called \"Python Data Science Handbook\". https://github.com/jakevdp/PythonDataScienceHandbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "Data manipulation in Python is nearly synonymous with NumPy array manipulation: even tools like Pandas are built around the NumPy array. This section will present several examples of using NumPy array manipulation to access data and subarrays, and to split, reshape, and join the arrays.  \n",
    "\n",
    "[The Basics of NumPy Arrays](PythonDataScienceHandbook/02.02-The-Basics-Of-NumPy-Arrays.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Objects - Series, DataFrame, and Index\n",
    "At the very basic level, Pandas objects can be thought of as enhanced versions of NumPy structured arrays in which the rows and columns are identified with labels rather than simple integer indices.  \n",
    "* Series - a one-dimensional array of indexed data, structured around a numpy array\n",
    "* DataFrame - a two-dimensional array (matrix/table), structures as an ordered sequence of one-dimensional Series array columns\n",
    "* Index - an immutable array used in Series and DataFrames  \n",
    "  \n",
    "[Introducing Pandas Objects](PythonDataScienceHandbook/03.01-Introducing-Pandas-Objects.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Index  \n",
    "The dataframe index represents the \"rows\" of the dataframe and is an important construct that serves three primary purposes:  \n",
    "* Identification - used to identify a particular row in the data frame  \n",
    "* Selection - used to select values in the dataframe  \n",
    "* Alignment - used to align data values between two or more series for concatinations, computations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:38:31.262272Z",
     "start_time": "2020-04-02T14:38:29.926428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n",
      "RangeIndex(start=0, stop=193, step=1)\n",
      "Index(['country', 'beer_servings', 'spirit_servings', 'wine_servings',\n",
      "       'total_litres_of_pure_alcohol', 'continent'],\n",
      "      dtype='object')\n",
      "(193, 6)\n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "6    Argentina            193               25            221   \n",
      "20     Bolivia            167               41              8   \n",
      "23      Brazil            245              145             16   \n",
      "35       Chile            130              124            172   \n",
      "37    Colombia            159               76              3   \n",
      "52     Ecuador            162               74              3   \n",
      "72      Guyana             93              302              1   \n",
      "132   Paraguay            213              117             74   \n",
      "133       Peru            163              160             21   \n",
      "163   Suriname            128              178              7   \n",
      "185    Uruguay            115               35            220   \n",
      "188  Venezuela            333              100              3   \n",
      "\n",
      "     total_litres_of_pure_alcohol      continent  \n",
      "6                             8.3  South America  \n",
      "20                            3.8  South America  \n",
      "23                            7.2  South America  \n",
      "35                            7.6  South America  \n",
      "37                            4.2  South America  \n",
      "52                            4.2  South America  \n",
      "72                            7.1  South America  \n",
      "132                           7.3  South America  \n",
      "133                           6.1  South America  \n",
      "163                           5.6  South America  \n",
      "185                           6.6  South America  \n",
      "188                           7.7  South America  \n"
     ]
    }
   ],
   "source": [
    "drinks4index = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "# identification\n",
    "print(drinks4index.head())\n",
    "print(drinks4index.index)\n",
    "print(drinks4index.columns)\n",
    "# the index and the columns are NOT part of the data\n",
    "print(drinks4index.shape)\n",
    "# the index values stay with their rows (they are immutable) when filtering so you can identify which row you are working with\n",
    "print(drinks4index[drinks4index.continent=='South America'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:38:33.028898Z",
     "start_time": "2020-04-02T14:38:33.017598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "#selection\n",
    "# pull out a specific data value by using the row (index) designation\n",
    "print(drinks4index.loc[23, 'beer_servings']) # grabs Brazil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:38:40.226049Z",
     "start_time": "2020-04-02T14:38:40.206067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             beer_servings  spirit_servings  wine_servings  \\\n",
      "country                                                      \n",
      "Afghanistan              0                0              0   \n",
      "Albania                 89              132             54   \n",
      "Algeria                 25                0             14   \n",
      "Andorra                245              138            312   \n",
      "Angola                 217               57             45   \n",
      "\n",
      "             total_litres_of_pure_alcohol continent  \n",
      "country                                              \n",
      "Afghanistan                           0.0      Asia  \n",
      "Albania                               4.9    Europe  \n",
      "Algeria                               0.7    Africa  \n",
      "Andorra                              12.4    Europe  \n",
      "Angola                                5.9    Africa  \n",
      "Index(['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola',\n",
      "       'Antigua & Barbuda', 'Argentina', 'Armenia', 'Australia', 'Austria',\n",
      "       ...\n",
      "       'Tanzania', 'USA', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela',\n",
      "       'Vietnam', 'Yemen', 'Zambia', 'Zimbabwe'],\n",
      "      dtype='object', name='country', length=193)\n",
      "(193, 5)\n"
     ]
    }
   ],
   "source": [
    "# set the index to different, more meaningful, values\n",
    "drinks4index.set_index('country', inplace=True)\n",
    "print(drinks4index.head())\n",
    "print(drinks4index.index)\n",
    "print(drinks4index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:39:54.186002Z",
     "start_time": "2020-04-02T14:39:54.174627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n"
     ]
    }
   ],
   "source": [
    "# new selection\n",
    "print(drinks.loc['Brazil', 'beer_servings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:42:36.438686Z",
     "start_time": "2020-04-02T14:42:36.422092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n"
     ]
    }
   ],
   "source": [
    "# set the index back to integers\n",
    "drinks.reset_index(inplace=True)\n",
    "print(drinks.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T14:47:45.366178Z",
     "start_time": "2020-04-02T14:47:45.137952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       beer_servings  spirit_servings  wine_servings  \\\n",
      "count     193.000000       193.000000     193.000000   \n",
      "mean      106.160622        80.994819      49.450777   \n",
      "std       101.143103        88.284312      79.697598   \n",
      "min         0.000000         0.000000       0.000000   \n",
      "25%        20.000000         4.000000       1.000000   \n",
      "50%        76.000000        56.000000       8.000000   \n",
      "75%       188.000000       128.000000      59.000000   \n",
      "max       376.000000       438.000000     370.000000   \n",
      "\n",
      "       total_litres_of_pure_alcohol  \n",
      "count                    193.000000  \n",
      "mean                       4.717098  \n",
      "std                        3.773298  \n",
      "min                        0.000000  \n",
      "25%                        1.300000  \n",
      "50%                        4.200000  \n",
      "75%                        7.200000  \n",
      "max                       14.400000  \n",
      "Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')\n",
      "Index(['beer_servings', 'spirit_servings', 'wine_servings',\n",
      "       'total_litres_of_pure_alcohol'],\n",
      "      dtype='object')\n",
      "beer_servings                   20.0\n",
      "spirit_servings                  4.0\n",
      "wine_servings                    1.0\n",
      "total_litres_of_pure_alcohol     1.3\n",
      "Name: 25%, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# many methods return dataframes with an index\n",
    "print(drinks.describe())\n",
    "print(drinks.describe().index)\n",
    "print(drinks.describe().columns)\n",
    "print(drinks.describe().loc['25%', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T16:50:07.254061Z",
     "start_time": "2020-04-02T16:50:05.897244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Asia\n",
      "1    Europe\n",
      "2    Africa\n",
      "3    Europe\n",
      "4    Africa\n",
      "Name: continent, dtype: object\n",
      "country\n",
      "Afghanistan      Asia\n",
      "Albania        Europe\n",
      "Algeria        Africa\n",
      "Andorra        Europe\n",
      "Angola         Africa\n",
      "Name: continent, dtype: object\n"
     ]
    }
   ],
   "source": [
    "drinks4index = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "# alignment\n",
    "# series always has an index that comes frm the dataframe\n",
    "print(drinks4index.continent.head())\n",
    "\n",
    "# reset the index\n",
    "drinks4index.set_index('country', inplace=True)\n",
    "print(drinks4index.continent.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T21:51:09.419531Z",
     "start_time": "2020-04-02T21:51:09.392291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa           53\n",
      "Europe           45\n",
      "Asia             44\n",
      "North America    23\n",
      "Oceania          16\n",
      "South America    12\n",
      "Name: continent, dtype: int64\n",
      "[53 45 44 23 16 12]\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "# working with series and indexes\n",
    "print(drinks4index.continent.value_counts())\n",
    "# now the values\n",
    "print(drinks4index.continent.value_counts().values)\n",
    "# find the value in the series for a specific index\n",
    "print(drinks4index.continent.value_counts()['Africa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T21:53:15.579507Z",
     "start_time": "2020-04-02T21:53:15.521074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South America    12\n",
      "Oceania          16\n",
      "North America    23\n",
      "Asia             44\n",
      "Europe           45\n",
      "Africa           53\n",
      "Name: continent, dtype: int64\n",
      "Africa           53\n",
      "Asia             44\n",
      "Europe           45\n",
      "North America    23\n",
      "Oceania          16\n",
      "South America    12\n",
      "Name: continent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# sorting series with indexes\n",
    "# sort the values\n",
    "print(drinks4index.continent.value_counts().sort_values())\n",
    "# sort the indices\n",
    "print(drinks4index.continent.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T22:12:09.972483Z",
     "start_time": "2020-04-02T22:12:09.939434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albania    3000000\n",
      "Andorra      85000\n",
      "Name: population, dtype: int64\n",
      "Afghanistan            NaN\n",
      "Albania        267000000.0\n",
      "Algeria                NaN\n",
      "Andorra         20825000.0\n",
      "Angola                 NaN\n",
      "dtype: float64\n",
      "             beer_servings  spirit_servings  wine_servings  \\\n",
      "Afghanistan              0                0              0   \n",
      "Albania                 89              132             54   \n",
      "Algeria                 25                0             14   \n",
      "Andorra                245              138            312   \n",
      "Angola                 217               57             45   \n",
      "\n",
      "             total_litres_of_pure_alcohol continent  population  \n",
      "Afghanistan                           0.0      Asia         NaN  \n",
      "Albania                               4.9    Europe   3000000.0  \n",
      "Algeria                               0.7    Africa         NaN  \n",
      "Andorra                              12.4    Europe     85000.0  \n",
      "Angola                                5.9    Africa         NaN  \n"
     ]
    }
   ],
   "source": [
    "# working with alignment in series\n",
    "people = pd.Series([3000000, 85000], index=['Albania', 'Andorra'], name='population')\n",
    "print(people)\n",
    "# now do math between two series\n",
    "print((drinks4index.beer_servings * people).head())\n",
    "\n",
    "# the indicies between the two series align (match-up) to perform the math calculations\n",
    "# concatenate two series based on alignment of the indexes\n",
    "print(pd.concat([drinks4index, people], axis=1, sort=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe MultiIndex  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T23:25:13.833782Z",
     "start_time": "2020-04-03T23:25:12.917833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Close    Volume Symbol\n",
      "0  2016-10-03   31.50  14070500   CSCO\n",
      "1  2016-10-03  112.52  21701800   AAPL\n",
      "2  2016-10-03   57.42  19189500   MSFT\n",
      "3  2016-10-04  113.00  29736800   AAPL\n",
      "4  2016-10-04   57.24  20085900   MSFT\n",
      "5  2016-10-04   31.35  18460400   CSCO\n",
      "6  2016-10-05   57.64  16726400   MSFT\n",
      "7  2016-10-05   31.59  11808600   CSCO\n",
      "8  2016-10-05  113.05  21453100   AAPL\n"
     ]
    }
   ],
   "source": [
    "stocks = pd.read_csv('http://bit.ly/smallstocks')\n",
    "print(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:25:21.195073Z",
     "start_time": "2020-04-03T01:25:21.097738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol  Date      \n",
      "AAPL    2016-10-03    112.52\n",
      "        2016-10-04    113.00\n",
      "        2016-10-05    113.05\n",
      "CSCO    2016-10-03     31.50\n",
      "        2016-10-04     31.35\n",
      "        2016-10-05     31.59\n",
      "MSFT    2016-10-03     57.42\n",
      "        2016-10-04     57.24\n",
      "        2016-10-05     57.64\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# form an aggregation with a multiIndex\n",
    "ser = stocks.groupby(['Symbol', 'Date']).Close.mean()\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:27:34.326114Z",
     "start_time": "2020-04-03T01:27:34.136005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date    2016-10-03  2016-10-04  2016-10-05\n",
      "Symbol                                    \n",
      "AAPL        112.52      113.00      113.05\n",
      "CSCO         31.50       31.35       31.59\n",
      "MSFT         57.42       57.24       57.64\n",
      "Date    2016-10-03  2016-10-04  2016-10-05\n",
      "Symbol                                    \n",
      "AAPL        112.52      113.00      113.05\n",
      "CSCO         31.50       31.35       31.59\n",
      "MSFT         57.42       57.24       57.64\n"
     ]
    }
   ],
   "source": [
    "# can unstack into a 2D dataframe\n",
    "print(ser.unstack())\n",
    "\n",
    "# or a pivot table\n",
    "print(stocks.pivot_table(values='Close', index='Symbol', columns='Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T01:32:02.894054Z",
     "start_time": "2020-04-03T01:32:02.665136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol  Date      \n",
      "AAPL    2016-10-03    112.52\n",
      "        2016-10-04    113.00\n",
      "        2016-10-05    113.05\n",
      "CSCO    2016-10-03     31.50\n",
      "        2016-10-04     31.35\n",
      "        2016-10-05     31.59\n",
      "MSFT    2016-10-03     57.42\n",
      "        2016-10-04     57.24\n",
      "        2016-10-05     57.64\n",
      "Name: Close, dtype: float64\n",
      "Date\n",
      "2016-10-03    112.52\n",
      "2016-10-04    113.00\n",
      "2016-10-05    113.05\n",
      "Name: Close, dtype: float64\n",
      "112.52\n",
      "Symbol\n",
      "AAPL    112.52\n",
      "CSCO     31.50\n",
      "MSFT     57.42\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# selecting from multiIndex series\n",
    "print(ser)\n",
    "# use outer index\n",
    "print(ser.loc['AAPL'])\n",
    "# use outer and inner\n",
    "print(ser.loc['AAPL', '2016-10-03'])\n",
    "# use just the inner\n",
    "print(ser.loc[:,'2016-10-03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T23:25:19.386382Z",
     "start_time": "2020-04-03T23:25:19.361768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Close    Volume\n",
      "Symbol Date                        \n",
      "CSCO   2016-10-03   31.50  14070500\n",
      "AAPL   2016-10-03  112.52  21701800\n",
      "MSFT   2016-10-03   57.42  19189500\n",
      "AAPL   2016-10-04  113.00  29736800\n",
      "MSFT   2016-10-04   57.24  20085900\n",
      "CSCO   2016-10-04   31.35  18460400\n",
      "MSFT   2016-10-05   57.64  16726400\n",
      "CSCO   2016-10-05   31.59  11808600\n",
      "AAPL   2016-10-05  113.05  21453100\n",
      "MultiIndex(levels=[['AAPL', 'CSCO', 'MSFT'], ['2016-10-03', '2016-10-04', '2016-10-05']],\n",
      "           codes=[[1, 0, 2, 0, 2, 1, 2, 1, 0], [0, 0, 0, 1, 1, 1, 2, 2, 2]],\n",
      "           names=['Symbol', 'Date'])\n"
     ]
    }
   ],
   "source": [
    "# set up multiIndex on dataframe\n",
    "stocks.set_index(['Symbol','Date'], inplace=True)\n",
    "print(stocks)\n",
    "print(stocks.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:42:25.507716Z",
     "start_time": "2020-04-04T15:42:25.451129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Close    Volume\n",
      "Symbol Date                        \n",
      "AAPL   2016-10-03  112.52  21701800\n",
      "       2016-10-04  113.00  29736800\n",
      "       2016-10-05  113.05  21453100\n",
      "CSCO   2016-10-03   31.50  14070500\n",
      "       2016-10-04   31.35  18460400\n",
      "       2016-10-05   31.59  11808600\n",
      "MSFT   2016-10-03   57.42  19189500\n",
      "       2016-10-04   57.24  20085900\n",
      "       2016-10-05   57.64  16726400\n",
      "             Close    Volume\n",
      "Date                        \n",
      "2016-10-03  112.52  21701800\n",
      "2016-10-04  113.00  29736800\n",
      "2016-10-05  113.05  21453100\n",
      "Close          112.52\n",
      "Volume    21701800.00\n",
      "Name: (AAPL, 2016-10-03), dtype: float64\n",
      "112.52\n",
      "                    Close    Volume\n",
      "Symbol Date                        \n",
      "AAPL   2016-10-03  112.52  21701800\n",
      "MSFT   2016-10-03   57.42  19189500\n",
      "Symbol  Date      \n",
      "AAPL    2016-10-03    112.52\n",
      "MSFT    2016-10-03     57.42\n",
      "Name: Close, dtype: float64\n",
      "Symbol  Date      \n",
      "AAPL    2016-10-03    112.52\n",
      "        2016-10-04    113.00\n",
      "Name: Close, dtype: float64\n",
      "Symbol  Date      \n",
      "AAPL    2016-10-03    112.52\n",
      "        2016-10-04    113.00\n",
      "CSCO    2016-10-03     31.50\n",
      "        2016-10-04     31.35\n",
      "MSFT    2016-10-03     57.42\n",
      "        2016-10-04     57.24\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# sort by the outer and inner indexes\n",
    "stocks.sort_index(inplace=True)\n",
    "print(stocks)\n",
    "# get just the APPL stock data\n",
    "print(stocks.loc['AAPL'])\n",
    "# get all data in a specific row\n",
    "print(stocks.loc[('AAPL', '2016-10-03'), :])\n",
    "# get data in a specific row and column\n",
    "print(stocks.loc[('AAPL', '2016-10-03'), 'Close'])\n",
    "# get data from two different rows with two different outer indexes\n",
    "print(stocks.loc[(['AAPL', 'MSFT'], '2016-10-03'), :])\n",
    "# get just the closing price for the two stocks\n",
    "print(stocks.loc[(['AAPL', 'MSFT'], '2016-10-03'), 'Close'])\n",
    "# get just the closing price for two dates for just AAPL stock\n",
    "print(stocks.loc[('AAPL', ['2016-10-03', '2016-10-04']), 'Close'])\n",
    "# get the closing price for two dates for all stocks\n",
    "print(stocks.loc[(slice(None), ['2016-10-03', '2016-10-04']), 'Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T15:52:30.844085Z",
     "start_time": "2020-04-04T15:52:28.975799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Close\n",
      "Symbol Date              \n",
      "CSCO   2016-10-03   31.50\n",
      "AAPL   2016-10-03  112.52\n",
      "MSFT   2016-10-03   57.42\n",
      "AAPL   2016-10-04  113.00\n",
      "MSFT   2016-10-04   57.24\n",
      "CSCO   2016-10-04   31.35\n",
      "MSFT   2016-10-05   57.64\n",
      "CSCO   2016-10-05   31.59\n",
      "AAPL   2016-10-05  113.05\n",
      "                     Volume\n",
      "Symbol Date                \n",
      "CSCO   2016-10-03  14070500\n",
      "AAPL   2016-10-03  21701800\n",
      "MSFT   2016-10-03  19189500\n",
      "AAPL   2016-10-04  29736800\n",
      "MSFT   2016-10-04  20085900\n",
      "CSCO   2016-10-04  18460400\n",
      "MSFT   2016-10-05  16726400\n",
      "CSCO   2016-10-05  11808600\n",
      "AAPL   2016-10-05  21453100\n",
      "                    Close    Volume\n",
      "Symbol Date                        \n",
      "CSCO   2016-10-03   31.50  14070500\n",
      "AAPL   2016-10-03  112.52  21701800\n",
      "MSFT   2016-10-03   57.42  19189500\n",
      "AAPL   2016-10-04  113.00  29736800\n",
      "MSFT   2016-10-04   57.24  20085900\n",
      "CSCO   2016-10-04   31.35  18460400\n",
      "MSFT   2016-10-05   57.64  16726400\n",
      "CSCO   2016-10-05   31.59  11808600\n",
      "AAPL   2016-10-05  113.05  21453100\n"
     ]
    }
   ],
   "source": [
    "# concatenate two dataframes using a multiIndex\n",
    "close = pd.read_csv('http://bit.ly/smallstocks', usecols=[0,1,3], index_col=['Symbol', 'Date'])\n",
    "print(close)\n",
    "volume = pd.read_csv('http://bit.ly/smallstocks', usecols=[0,2,3], index_col=['Symbol', 'Date'])\n",
    "print(volume)\n",
    "# now concat the two dataframes using merge\n",
    "both = pd.merge(close, volume, left_index=True, right_index=True)\n",
    "print(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Dictionaries\n",
    "Unlike other Python data structures such as lists, tuples, strings, and sets which have only a value as an element, a dictionary as a key-value pair. Unlike lists which can only contain homogeneous types, a dictionary can store many kinds of data, including lists and other dictionaries in a single dictionary. Where lists have indices as integers, dictionaries use keys as indices. Dictionary keys can be any immutable type; strings and numbers can always be keys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable object either directly or indirectly, it cannot be used as a key. You cant use lists as keys, since lists can be modified in place  \n",
    "  \n",
    "This section on dictionaries is respectfully reused from an excellent article by Chamanth mvs  \n",
    "https://medium.com/analytics-vidhya/python-dictionaries-in-and-out-f1b7a3237a65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation and Accessing Dictionaries\n",
    "**Creation** - there are various methods in creating a dictionary. Values can be of any data-type(ranging from int to nested dictionaries). Unlike lists, where lists have indices as integers (0,1,2) but in dictionaries, Keys are considered as indices and they can be of mixed types like (int, float, boolean, string).  \n",
    "**Accessing** - unlike Lists, Dictionaries are unordered collection of items. So, they cant be indexed (like done in a list, for example-List[0]=> to access first element in the list). Dictionaries can only be accessed using keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T16:06:36.555260Z",
     "start_time": "2019-11-02T16:06:36.542843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UniversityName': 'MIT', 'YearOfEstablishment': 1861, 'TypeOfInstitution': 'Private', 'NumberOfStudents': 11574}\n",
      "{'UniversityName': 'MIT', 'YearOfEstablishment': 1861, 'TypeOfInstitute': 'Private', 'NumberOfStudents': 11574}\n",
      "{'UniversityName': 'MIT', 'YearOfEstablishment': 1861, 'TypeOfInstitution': 'Private', 'NumberOfStudents': 11574}\n"
     ]
    }
   ],
   "source": [
    "# creating a dictionary\n",
    "\n",
    "# method 1 - using the dict() function\n",
    "university_dict = dict(UniversityName=\"MIT\", YearOfEstablishment=1861, \n",
    "                       TypeOfInstitution=\"Private\", NumberOfStudents=11574)\n",
    "\n",
    "print(university_dict)\n",
    "\n",
    "# method 2 - using key-value pairs in {}\n",
    "university_dict = {\"UniversityName\":\"MIT\", \"YearOfEstablishment\":1861, \n",
    "                  \"TypeOfInstitute\":\"Private\", \"NumberOfStudents\":11574}\n",
    "\n",
    "print(university_dict)\n",
    "\n",
    "# method 3 - sing a list of tuples and the dict() function\n",
    "university_dict = dict([(\"UniversityName\",\"MIT\"), (\"YearOfEstablishment\",1861),\n",
    "                      (\"TypeOfInstitution\",\"Private\"), (\"NumberOfStudents\",11574)])\n",
    "\n",
    "print(university_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T16:07:03.264919Z",
     "start_time": "2019-11-02T16:07:03.251679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT\n",
      "11574\n"
     ]
    }
   ],
   "source": [
    "#accessing a dictionary - using keys\n",
    "print(university_dict[\"UniversityName\"])\n",
    "print(university_dict[\"NumberOfStudents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration in Dictionaries\n",
    "Iterating through dictionaries are quite different from other data structures because, in dictionaries we have (key-value) pairs whereas, in lists or tuples we only have one single element at each index, also a list on its own is iterable.  \n",
    "In order to extract values from dictionary , we need to use .values() method. Similarly, we need to use .keys() method to iterate over keys in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T16:19:40.441235Z",
     "start_time": "2019-11-02T16:19:40.427884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT\n",
      "1861\n",
      "Private\n",
      "11574\n",
      "UniversityName\n",
      "YearOfEstablishment\n",
      "TypeOfInstitution\n",
      "NumberOfStudents\n"
     ]
    }
   ],
   "source": [
    "# iteration in dictionaries using values\n",
    "for each_element in university_dict.values():\n",
    "    print(each_element)\n",
    "    \n",
    "# iteration in dictionaries using keys\n",
    "for each_element in university_dict.keys():\n",
    "    print(each_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehension in Dictionaries\n",
    "Similar to list comprehension, dictionary comprehensions provide a concise way to create dictionaries. Common applications are to make new dictionaries where each element is the result of some operations applied to each member of another sequence or iterable, or to create a subsequence of those elements that satisfy a certain condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T16:32:20.136400Z",
     "start_time": "2019-11-02T16:32:20.125219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1, 2: 4, 3: 9, 4: 16, 5: 25}\n",
      "{1: 'odd', 2: 'even', 3: 'odd', 4: 'even', 5: 'odd'}\n"
     ]
    }
   ],
   "source": [
    "# dictionary comprehension\n",
    "# to generate the square of the corresponding number\n",
    "squared_numbers = {number:number**2 for number in [1,2,3,4,5]}\n",
    "print(squared_numbers)\n",
    "\n",
    "# dictionary comprehension using conditional logic\n",
    "# to identify if number is even or odd\n",
    "number_list = [1,2,3,4,5]\n",
    "oddeven_numbers = {number:(\"even\" if number%2 == 0 else \"odd\") for number in number_list}\n",
    "print(oddeven_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods in Dictionaries\n",
    "**clear()** - clears all the keys and values in a dictionary but it doesnt delete entire dictionary object from memory.    \n",
    "**copy()** - creates a duplicate dictionary in different address of the memory.  \n",
    "**get()** - retrieves a key in an object and return None instead of keyError, if the key doesnt exist. The biggest advantage is that, it doesnt throw an error, even though if we try to access a key, which is not present in dictionary.  \n",
    "**pop()** - removes that particular (key-value) pair from dictionary by returning the value corresponding to the key that was removed.  \n",
    "**popitem()** - randomly remove (key-value) pair from the dictionary.  \n",
    "**update()** - will change (key,value) in a dictionary with another set of key-value pairs. It will also overwrite an existing key.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T14:48:10.410219Z",
     "start_time": "2019-11-03T14:48:10.380279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{}\n",
      "1\n",
      "None\n",
      "{'b': 2, 'c': 3}\n",
      "the key is not present in the dictionary\n",
      "('c', 3)\n",
      "{'a': 1, 'b': 2}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{'a': 'changed', 'b': 2, 'c': 3}\n",
      "{'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "# dictionary methods\n",
    "sample_dict = {\"a\":1, \"b\":2, \"c\":3}\n",
    "print(sample_dict)\n",
    "\n",
    "# copy()\n",
    "sample_dict_clone = sample_dict.copy()\n",
    "print(sample_dict_clone)\n",
    "\n",
    "# clear()\n",
    "sample_dict_clone.clear()\n",
    "print(sample_dict_clone)\n",
    "\n",
    "# get()\n",
    "print(sample_dict.get('a'))\n",
    "print(sample_dict.get('d'))\n",
    "\n",
    "# pop()\n",
    "sample_dict_clone = sample_dict.copy()\n",
    "sample_dict_clone.pop('a')\n",
    "print(sample_dict_clone)\n",
    "# providing an option message will overcome an error if the key does not exist in the dictionary\n",
    "print(sample_dict_clone.pop('d', \"the key is not present in the dictionary\"))\n",
    "\n",
    "# popitem()\n",
    "sample_dict_clone = sample_dict.copy()\n",
    "print(sample_dict_clone.popitem())\n",
    "print(sample_dict_clone)\n",
    "\n",
    "# update\n",
    "new_dict = {}\n",
    "new_dict.update(sample_dict)\n",
    "print(new_dict)\n",
    "\n",
    "new_dict['a']=\"changed\"\n",
    "print(new_dict)\n",
    "\n",
    "new_dict.update(sample_dict)\n",
    "print(new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='special_features'></a>\n",
    "## Special Features\n",
    "This section contains some handy features and shortcuts associated with Pandas dataframes and series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_operations'></a>\n",
    "### Element-wise Operations on Series and DataFrames (Univeral Functions - ufunc)\n",
    "One of the essential pieces of NumPy is the ability to perform quick element-wise operations, both with basic arithmetic (addition, subtraction, multiplication, etc.) and with more sophisticated operations (trigonometric functions, exponential and logarithmic functions, etc.). Pandas inherits much of this functionality from NumPy, but includes a couple useful twists, however: for unary operations like negation and trigonometric functions, these ufuncs will preserve index and column labels in the output, and for binary operations such as addition and multiplication, Pandas will automatically align indices when passing the objects to the ufunc.  \n",
    "  \n",
    "[Operating on Data in Pandas](PythonDataScienceHandbook/03.03-Operations-in-Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
